{"name":"Somoclu","tagline":"Massively parallel self-organizing maps","body":"Somoclu\r\n=======\r\nSomoclu is a massively parallel implementation of self-organizing maps. It exploits multicore CPUs, it is able to rely on MPI for distributing the workload in a cluster, and it can be accelerated by CUDA. A sparse kernel is also included, which is useful for training maps on vector spaces generated in text mining processes.\r\n\r\nKey features:\r\n\r\n* Fast execution by parallelization: OpenMP, MPI, and CUDA are supported.\r\n* Multi-platform: Linux, OS X, and Windows are supported.\r\n* Planar and toroid maps.\r\n* Rectangular and hexagonal grids.\r\n* Both dense and sparse input data are supported.\r\n* Large maps of several hundred thousand neurons are feasible.\r\n* Integration with [Databionic ESOM Tools](http://databionic-esom.sourceforge.net/).\r\n* [Python](http://somoclu.readthedocs.org/), [R](https://cran.r-project.org/web/packages/Rsomoclu/), and [MATLAB](https://github.com/peterwittek/somoclu/tree/master/src/MATLAB) interfaces for the dense CPU and GPU kernels.\r\n\r\nFor more information, refer to the following paper:\r\n\r\nPeter Wittek, Shi Chao Gao, Ik Soo Lim, Li Zhao (2015). Somoclu: An Efficient Parallel Library for Self-Organizing Maps. [arXiv:1305.1422](http://arxiv.org/abs/1305.1422).\r\n\r\nUsage\r\n===\r\nBasic Command Line Use\r\n----------------------\r\nSomoclu takes a plain text input file -- either dense or sparse data. Example files are included.\r\n\r\n    $ [mpirun -np NPROC] somoclu [OPTIONs] INPUT_FILE OUTPUT_PREFIX\r\n\r\nArguments:\r\n\r\n    -c FILENAME              Specify an initial codebook for the map.\r\n    -e NUMBER                Maximum number of epochs\r\n    -g TYPE                  Grid type: square or hexagonal (default: square)\r\n    -k NUMBER                Kernel type\r\n                                0: Dense CPU\r\n                                1: Dense GPU\r\n                                2: Sparse CPU\r\n    -m TYPE                  Map type: planar or toroid (default: planar)\r\n    -p NUMBER                Compact support for map update \r\n                             (0: false, 1: true, default: 0)\r\n    -t STRATEGY              Radius cooling strategy: linear or exponential (default: linear)\r\n    -r NUMBER                Start radius (default: half of the map in direction min(x,y))\r\n    -R NUMBER                End radius (default: 1)\r\n    -T STRATEGY              Learning rate cooling strategy: linear or exponential (default: linear)\r\n    -l NUMBER                Starting learning rate (default: 0.1)\r\n    -L NUMBER                Finishing learning rate (default: 0.01)\r\n    -s NUMBER                Save interim files (default: 0):\r\n                                0: Do not save interim files\r\n                                1: Save U-matrix only\r\n                                2: Also save codebook and best matching\r\n    -x, --columns NUMBER     Number of columns in map (size of SOM in direction x)\r\n    -y, --rows    NUMBER     Number of rows in map (size of SOM in direction y)\r\n\r\nExamples:\r\n\r\n    $ somoclu data/rgbs.txt data/rgbs\r\n    $ mpirun -np 4 somoclu -k 0 --rows 20 --columns 20 data/rgbs.txt data/rgbs\r\n\r\nWith random initialization, the initial codebook will be filled with random numbers ranging from 0 to 1. Either supply your own initial codebook or normalize your data to fall in this range.\r\n\r\nThe maps generated by the GPU and the CPU kernels are likely to be different. For computational efficiency, Somoclu uses single-precision floats. This occasionally results in identical distances between a data instance and the neurons. The CPU version will pick the best matching unit with the lowest coordinate values. Such sequentiality cannot be guaranteed in the reduction kernel of the GPU variant. This is not a bug, but it is better to be aware of it.\r\n\r\nEfficient Parallel and Distributed Execution\r\n--------------------------------------------\r\nThe CPU kernels use OpenMP to load multicore processors. On a single node, this is more efficient than launching tasks with MPI to match the number of cores. The MPI tasks replicated the codebook, which is especially inefficient for large maps. \r\n\r\nFor instance, given a single node with eight cores, the following execution will use 1/8th of the memory, and will run 10-20% faster:\r\n\r\n    $ somoclu -x 200 -y 200 data/rgbs.txt data/rgbs\r\n\r\nOr, equivalently:\r\n\r\n    $ OMP_NUM_THREADS=8 somoclu -x 200 -y 200 data/rgbs.txt data/rgbs\r\n\r\nAvoid the following on a single node:\r\n\r\n    $ OMP_NUM_THREADS=1 mpirun -np 8 somoclu -x 200 -y 200 data/rgbs.txt data/rgbs\r\n\r\nThe same caveats apply for the sparse CPU kernel.\r\n\r\nVisualisation\r\n-------------\r\nThe primary purpose of generating a map is visualisation. Somoclu does not come with its own functions for visualisation, since there are numerous generic tools that are capable of plotting high-quality figures. \r\n\r\nThe output formats of the U-matrix and the codebook are compatible with [Databionic ESOM Tools](http://databionic-esom.sourceforge.net/) for more advanced visualisation.\r\n\r\n\r\nInput File Formats\r\n==================\r\nOne sparse and two dense data formats are supported. All of them are plain text files. The entries can be separated by any white-space character. One row represents one data instance across all formats. Comment lines starting with a hash mark are ignored.\r\n\r\nThe sparse format follows the [libsvm](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) guidelines. The first feature is zero-indexed. For instance, the vector [ 1.2 0 0 3.4] is represented as the following line in the file:\r\n0:1.2 3:3.4. The file is parsed twice: once to get the number of instances and features, and the second time to read the data in the individual threads.\r\n\r\nThe basic dense format includes the coordinates of the data vectors, separated by a white-space. Just like the sparse format, this file is parsed twice to get the basic dimensions right. \r\n\r\nThe .lrn file of [Databionic ESOM Tools](http://databionic-esom.sourceforge.net/) is also accepted and it is parsed only once. The format is described as follows:\r\n\r\n% n\r\n\r\n% m\r\n\r\n% s1\t\ts2\t\t\t..\t\tsm\r\n\r\n% var_name1\tvar_name2\t\t..\t\tvar_namem\t\r\n\r\nx11\t\tx12\t\t\t..\t\tx1m\r\n\r\nx21\t\tx22\t\t\t..\t\tx2m\r\n\r\n.\t\t.\t\t\t.\t\t.\r\n\r\n.\t\t.\t\t\t.\t\t.\r\n\r\nxn1\t\txn2\t\t\t..\t\txnm\r\n\r\nHere n is the number of rows in the file, that is, the number of data instances. Parameter m defines the number of columns in the file. The next row defines the column mask: the value 1 for a column means the column should be used in the training. Note that the first column in this format is always a unique key, so this should have the value 9 in the column mask. The row with the variable names is ignore by Somoclu. The elements of the matrix follow -- from here, the file is identical to the basic dense format, with the addition of the first column as the unique key.\r\n\r\nIf the input file is sparse, but a dense kernel is invoked, Somoclu will execute and results will be incorrect. Invoking a sparse kernel on a dense input file is likely to lead to a segmentation fault.\r\n\r\nInterfaces\r\n==========\r\n[Python](http://somoclu.readthedocs.org/), [R](https://cran.r-project.org/web/packages/Rsomoclu/), and [MATLAB](https://github.com/peterwittek/somoclu/tree/master/src/MATLAB) interfaces are available for the dense CPU  and GPU kernels. MPI and the sparse kernel are not support through the interfaces. For respective examples, see the folders in src.\r\n\r\nThe Python version is also available in [PyPI](https://pypi.python.org/pypi/somoclu). You can install it with\r\n\r\n    $ sudo pip install somoclu\r\n\r\nTo get it working with the GPU kernel, you might have to edit the setup.py file to specify your CUDA directory.\r\n    \r\nThe R version is available on CRAN. You can install it with\r\n    \r\n    install.packages(\"Rsomoclu\")\r\n\r\nTo get it working with the GPU kernel, download the source zip file and specify your CUDA directory the following way:\r\n\r\n    R CMD INSTALL src/Rsomoclu_version.tar.gz --configure-args=/path/to/cuda\r\n\r\nFor using the MATLAB toolbox, define the location of your MATLAB install to the configure script:\r\n\r\n    ./configure --without-mpi --with-matlab=/usr/local/MATLAB/R2014a\r\n\r\nFor the GPU kernel, specify the location of your CUDA library for the configure script. More detailed instructions are in the [MATLAB source folder](https://github.com/peterwittek/somoclu/tree/master/src/MATLAB).\r\n\r\nCompilation & Installation\r\n==========================\r\nThese are the instructions for compiling the core library and the command line interface. The only dependency is a C++ compiler chain -- GCC, ICC, and VC were tested.\r\n\r\nMulticore execution is supported through OpenMP -- the compiler must support this. Distributed systems are supported through MPI. The package was tested with OpenMPI. It should also work with other MPI flavours. CUDA support is optional.\r\n\r\nLinux or Mac OS X\r\n-----------------\r\nFrom GIT repository first run\r\n\r\n    $ ./autogen.sh\r\n\r\nThen follow the standard POSIX procedure:\r\n\r\n    $ ./configure [options]\r\n    $ make\r\n    $ make install\r\n\r\nUsing Intel compilers\r\n\r\n    export CC=/path/of/intel/compiler/icc\r\n    export CXX=/path/of/intel/compiler/icpc\r\n    export OMPI_CC=/path/of/intel/compiler/icc\r\n    export OMPI_CXX=/path/of/intel/compiler/icpc\r\n    \r\nIn order to use icc and icpc compilers, you have to set these variables\r\nso the mpic++ will invoke icpc instead of the default compiler.\r\n\r\nOptions for configure\r\n\r\n    --prefix=PATH           Set directory prefix for installation\r\n\r\n\r\nBy default Somoclu is installed into /usr/local. If you prefer a\r\ndifferent location, use this option to select an installation\r\ndirectory.\r\n\r\n    --without-mpi           Disregard any MPI installation found.\r\n    --with-mpi=MPIROOT      Use MPI root directory.\r\n    --with-mpi-compilers=DIR or --with-mpi-compilers=yes\r\n                              use MPI compiler (mpicxx) found in directory DIR, or\r\n                              in your PATH if =yes\r\n    --with-mpi-libs=\"LIBS\"  MPI libraries [default \"-lmpi\"]\r\n    --with-mpi-incdir=DIR   MPI include directory [default MPIROOT/include]\r\n    --with-mpi-libdir=DIR   MPI library directory [default MPIROOT/lib]\r\n\r\nThe above flags allow the identification of the correct MPI library the user wishes to use. The flags are especially useful if MPI is installed in a non-standard location, or when multiple MPI libraries are available.\r\n\r\n    --with-cuda=/path/to/cuda           Set path for CUDA\r\n\r\nSomoclu looks for CUDA in /usr/local/cuda. If your installation is not there, then specify the path with this parameter. If you do not want CUDA enabled, set the parameter to ```--without-cuda```.\r\n\r\nWindows\r\n-------\r\nUse the `somoclu.sln` under `src/Windows/somoclu` as an example Visual Studio 2013 solution. Modify the CUDA version or VC compiler version according to your needs. \r\n\r\nThe default solution enables all of OpenMP, MPI, and CUDA. The default MPI installation path is `C:\\Program Files\\Microsoft MPI`, modify the settings if yours is in a different path. The configuration default CUDA version is 6.5.  Disable MPI by removing `HAVE_MPI` macro in the project properties (`Properties -> Configuration Properties -> C/C++ -> Preprocessor`). Disable CUDA by removing `CUDA` macro in the solution properties.\r\n\r\nThe usage is identical to the Linux version through command line (see the relevant section). \r\n\r\nWhen using the Somoclu Python interface on Windows, if you encounter errors like: \r\n\r\n    ImportError: DLL load failed: The specified module could not be found\r\n    \r\nYou may need to find the right version (32/64bit) of `vcomp90.dll, msvcp90.dll, msvcr90.dll` and put to `C:\\Windows\\System32` or `C:\\Windows\\SysWOW64`.\r\n\r\nInstructions on building Python extension with CUDA support on Windows is at [here](https://github.com/peterwittek/somoclu/tree/master/src/Python).\r\n\r\nAcknowledgment\r\n==============\r\nThis work was supported by the European Commission Seventh Framework Programme under Grant Agreement Number FP7-601138 PERICLES and by the AWS in Education Machine Learning Grant award.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}